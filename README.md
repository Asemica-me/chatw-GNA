# AI-powered Chatbot for Geoportale Nazionale dell'Archeologia (GNA)

## ğŸŒ Overview

This repository contains the code for a **Question-Answering (QnA) application** designed to enhance user interaction and knowledge accessibility in the context of the [**Geoportale Nazionale dell'Archeologia (GNA)**](https://gna.cultura.gov.it/progetto.html) project. The application integrates **Retrieval-Augmented Generation (RAG)** and **Natural Language Processing (NLP)** techniques to streamline user operations, ensuring precise and context-aware responses based on the platformâ€™s [documentation](https://gna.cultura.gov.it/wiki/index.php/Pagina_principale).

The system is built using the **LangChain framework**, integrated with **Mistral AI** and **FAISS vector store**, and operates through a **Streamlit interface**.

## ğŸ¯ Objectives

The chatbot aims to provide a conversational interface for users, helping them navigate the GNA user manual efficiently. Key functionalities include:

- **Contextual, accurate responses** generated by the chatbot using generative AI.
- **Italian language support**, with potential for multilingual capabilities.
- Seamless **retrieval of information** from the structured dataset.

## ğŸ—ï¸ System Architecture

The application consists of the following components:
1. ğŸ“„ **Data Extraction**: Data is extracted from an XML sitemap and processed into a structured CSV dataset.
2. ğŸ”  **Vectorization**: Text chunks are converted into embeddings using **Mistral AI** and stored in **FAISS** for efficient querying.
3. ğŸ” **Retrieval Mechanism**: User queries are matched against the stored embeddings to retrieve semantically similar text.
4. ğŸ’¬ **Response Generation**: The **chosen LLM** - Mistral NeMo is suggested - generates context-aware responses based on the retrieved information.
5. ğŸ§  **Conversational Memory**: A memory buffer retains the context of the conversation, ensuring coherent interactions.

## â­ Key Features

- **Generative AI**: The chatbot generates responses based on context-aware retrieval.
- **Vector Store**: Efficient query retrieval using FAISS for storing text embeddings.
- **Streamlit Interface**: Custom user interface for easy interaction with the chatbot.
- **Multilingual Support**: Primarily in Italian with potential to expand.

## âš™ï¸ Installation

To run the chatbot application locally, follow these steps:

1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/chatw-GNA.git

2. Install the required dependencies:
   ```
   pip install -r requirements.txt
3. Set up your environment variables:
   - create a `.env` file in the root directory.
   - Add your API keys and other necessary configurations.
4. Run the application:
   ```bash
   streamlit run main.py
5. Open your browser and navigate to your local URL host to interact with the chatbot.
